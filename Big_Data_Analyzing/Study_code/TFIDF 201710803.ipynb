{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "\n",
    "os.environ[\"PYLIB\"]=os.path.join(os.environ[\"SPARK_HOME\"],'python','lib')\n",
    "sys.path.insert(0,os.path.join(os.environ[\"PYLIB\"],'py4j-0.10.1-src.zip'))\n",
    "sys.path.insert(0,os.path.join(os.environ[\"PYLIB\"],'pyspark.zip'))\n",
    "\n",
    "import pyspark\n",
    "myConf=pyspark.SparkConf()\n",
    "spark = pyspark.sql.SparkSession.builder\\\n",
    "    .master(\"local\")\\\n",
    "    .appName(\"myApp\")\\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"C:/Users/JSM\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark를 이용한 텍스트 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "doc2d=[\n",
    "    [\"When I find myself in times of trouble\"],\n",
    "    [\"Mother Mary comes to me\"],\n",
    "    [\"Speaking words of wisdom, let it be\"],\n",
    "    [\"And in my hour of darkness\"],\n",
    "    [\"She is standing right in front of me\"],\n",
    "    [\"Speaking words of wisdom, let it be\"],\n",
    "    [u\"우리 Let it be\"],\n",
    "    [u\"나 Let it be\"],\n",
    "    [u\"너 Let it be\"],\n",
    "    [\"Let it be\"],\n",
    "    [\"Whisper words of wisdom, let it be\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                sent|\n",
      "+--------------------+\n",
      "|When I find mysel...|\n",
      "|Mother Mary comes...|\n",
      "|Speaking words of...|\n",
      "|And in my hour of...|\n",
      "|She is standing r...|\n",
      "|Speaking words of...|\n",
      "|        우리 Let it be|\n",
      "|         나 Let it be|\n",
      "|         너 Let it be|\n",
      "|           Let it be|\n",
      "|Whisper words of ...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDf = spark.createDataFrame(doc2d, ['sent'])\n",
    "myDf.show(truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+-----------------------------------------------+\n",
      "|sent                                  |words                                          |\n",
      "+--------------------------------------+-----------------------------------------------+\n",
      "|When I find myself in times of trouble|[when, i, find, myself, in, times, of, trouble]|\n",
      "|Mother Mary comes to me               |[mother, mary, comes, to, me]                  |\n",
      "|Speaking words of wisdom, let it be   |[speaking, words, of, wisdom,, let, it, be]    |\n",
      "+--------------------------------------+-----------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tokenizer : 단어로 쪼개기\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "tokenizer = Tokenizer(inputCol=\"sent\", outputCol=\"words\") #토크나이저 객체 생성\n",
    "\n",
    "tokDf = tokenizer.transform(myDf) #토크나이저 함수를 DF에 적용(transform)\n",
    "tokDf.show(3, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(sent=u'When I find myself in times of trouble', words=[u'when', u'i', u'find', u'myself', u'in', u'times', u'of', u'trouble'])\n",
      "Row(sent=u'Mother Mary comes to me', words=[u'mother', u'mary', u'comes', u'to', u'me'])\n",
      "Row(sent=u'Speaking words of wisdom, let it be', words=[u'speaking', u'words', u'of', u'wisdom,', u'let', u'it', u'be'])\n"
     ]
    }
   ],
   "source": [
    "for r in tokDf.select(\"sent\", \"words\").take(3):\n",
    "    print r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i me my myself we our ours ourselves you your yours yourself yourselves he him his himself she her hers herself it its itself they them their theirs themselves what which who whom this that these those am is are was were be been being have has had having do does did doing a an the and but if or because as until while of at by for with about against between into through during before after above below to from up down in out on off over under again further then once here there when where why how all any both each few more most other some such no nor not only own same so than too very s t can will just don should now d ll m o re ve y ain aren couldn didn doesn hadn hasn haven isn ma mightn mustn needn shan shouldn wasn weren won wouldn 가 는 우리 나 너\n"
     ]
    }
   ],
   "source": [
    "#Stopwords : 불용어 처리 기구\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "stop = StopWordsRemover(inputCol=\"words\", outputCol=\"nostops\")\n",
    "\n",
    "stopwords=list() #기존에 있는 스탑워드를 더한다\n",
    "_stopwords=stop.getStopWords()\n",
    "for e in _stopwords:\n",
    "    stopwords.append(e)\n",
    "    \n",
    "_mystopwords=[u\"가\", u\"는\", u\"우리\", u\"나\", u\"너\"]\n",
    "for e in _mystopwords:\n",
    "        stopwords.append(e)\n",
    "stop.setStopWords(stopwords) #stop에 stopwords를 입력\n",
    "\n",
    "for e in stop.getStopWords():\n",
    "    print e,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                sent|               words|             nostops|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|When I find mysel...|[when, i, find, m...|[find, times, tro...|\n",
      "|Mother Mary comes...|[mother, mary, co...|[mother, mary, co...|\n",
      "|Speaking words of...|[speaking, words,...|[speaking, words,...|\n",
      "|And in my hour of...|[and, in, my, hou...|    [hour, darkness]|\n",
      "|She is standing r...|[she, is, standin...|[standing, right,...|\n",
      "|Speaking words of...|[speaking, words,...|[speaking, words,...|\n",
      "|        우리 Let it be|   [우리, let, it, be]|               [let]|\n",
      "|         나 Let it be|    [나, let, it, be]|               [let]|\n",
      "|         너 Let it be|    [너, let, it, be]|               [let]|\n",
      "|           Let it be|       [let, it, be]|               [let]|\n",
      "|Whisper words of ...|[whisper, words, ...|[whisper, words, ...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stopDf = stop.transform(tokDf)\n",
    "stopDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|                sent|               words|             nostops|                  cv|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|When I find mysel...|[when, i, find, m...|[find, times, tro...|(16,[5,6,8],[1.0,...|\n",
      "|Mother Mary comes...|[mother, mary, co...|[mother, mary, co...|(16,[10,13,14],[1...|\n",
      "|Speaking words of...|[speaking, words,...|[speaking, words,...|(16,[0,1,2,3],[1....|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------------+--------------------+--------------------+\n",
      "|                sent|             nostops|                  cv|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|When I find mysel...|[find, times, tro...|(16,[5,6,8],[1.0,...|\n",
      "|Mother Mary comes...|[mother, mary, co...|(16,[10,13,14],[1...|\n",
      "|Speaking words of...|[speaking, words,...|(16,[0,1,2,3],[1....|\n",
      "|And in my hour of...|    [hour, darkness]|(16,[7,9],[1.0,1.0])|\n",
      "|She is standing r...|[standing, right,...|(16,[4,12,15],[1....|\n",
      "|Speaking words of...|[speaking, words,...|(16,[0,1,2,3],[1....|\n",
      "|        우리 Let it be|               [let]|      (16,[0],[1.0])|\n",
      "|         나 Let it be|               [let]|      (16,[0],[1.0])|\n",
      "|         너 Let it be|               [let]|      (16,[0],[1.0])|\n",
      "|           Let it be|               [let]|      (16,[0],[1.0])|\n",
      "|Whisper words of ...|[whisper, words, ...|(16,[0,1,2,11],[1...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#countVectorizer\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "cv = CountVectorizer(inputCol = \"nostops\", outputCol = \"cv\", vocabSize =30, minDF=1.0 ) \n",
    "#vocabSize : 단어 갯수, minDF: 단어가 문서에 사용된 비율\n",
    "cvModel =cv.fit(stopDf) #CVmodel 생성(Estimator)\n",
    "\n",
    "\n",
    "cvDf = cvModel.transform(stopDf)\n",
    "cvDf.show(3)\n",
    "\n",
    "cvDf.select('sent', 'nostops', 'cv').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                sent|             nostops|                hash|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|When I find mysel...|[find, times, tro...|(50,[10,24,43],[1...|\n",
      "|Mother Mary comes...|[mother, mary, co...|(50,[1,21,24],[1....|\n",
      "|Speaking words of...|[speaking, words,...|(50,[9,12,14,41],...|\n",
      "|And in my hour of...|    [hour, darkness]|(50,[23,27],[1.0,...|\n",
      "|She is standing r...|[standing, right,...|(50,[24,43,46],[1...|\n",
      "|Speaking words of...|[speaking, words,...|(50,[9,12,14,41],...|\n",
      "|        우리 Let it be|               [let]|     (50,[14],[1.0])|\n",
      "|         나 Let it be|               [let]|     (50,[14],[1.0])|\n",
      "|         너 Let it be|               [let]|     (50,[14],[1.0])|\n",
      "|           Let it be|               [let]|     (50,[14],[1.0])|\n",
      "|Whisper words of ...|[whisper, words, ...|(50,[9,14,15,41],...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "\n",
    "hashTF = HashingTF(inputCol = \"nostops\", outputCol = \"hash\", numFeatures=50)\n",
    "\n",
    "hashDf = hashTF.transform(stopDf)\n",
    "\n",
    "hashDf.select('sent', 'nostops', 'hash').show() #hashTF를 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                sent|               words|             nostops|                hash|                 idf|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|When I find mysel...|[when, i, find, m...|[find, times, tro...|(50,[10,24,43],[1...|(50,[10,24,43],[1...|\n",
      "|Mother Mary comes...|[mother, mary, co...|[mother, mary, co...|(50,[1,21,24],[1....|(50,[1,21,24],[1....|\n",
      "|Speaking words of...|[speaking, words,...|[speaking, words,...|(50,[9,12,14,41],...|(50,[9,12,14,41],...|\n",
      "|And in my hour of...|[and, in, my, hou...|    [hour, darkness]|(50,[23,27],[1.0,...|(50,[23,27],[1.79...|\n",
      "|She is standing r...|[she, is, standin...|[standing, right,...|(50,[24,43,46],[1...|(50,[24,43,46],[1...|\n",
      "|Speaking words of...|[speaking, words,...|[speaking, words,...|(50,[9,12,14,41],...|(50,[9,12,14,41],...|\n",
      "|        우리 Let it be|   [우리, let, it, be]|               [let]|     (50,[14],[1.0])|(50,[14],[0.40546...|\n",
      "|         나 Let it be|    [나, let, it, be]|               [let]|     (50,[14],[1.0])|(50,[14],[0.40546...|\n",
      "|         너 Let it be|    [너, let, it, be]|               [let]|     (50,[14],[1.0])|(50,[14],[0.40546...|\n",
      "|           Let it be|       [let, it, be]|               [let]|     (50,[14],[1.0])|(50,[14],[0.40546...|\n",
      "|Whisper words of ...|[whisper, words, ...|[whisper, words, ...|(50,[9,14,15,41],...|(50,[9,14,15,41],...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idf =IDF(inputCol = \"hash\", outputCol = \"idf\")\n",
    "idfModel = idf.fit(hashDf)\n",
    "idfDf = idfModel.transform(hashDf)\n",
    "\n",
    "idfDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(nostops=[u'find', u'times', u'trouble'], hash=SparseVector(50, {10: 1.0, 24: 1.0, 43: 1.0}))\n",
      "Row(nostops=[u'mother', u'mary', u'comes'], hash=SparseVector(50, {1: 1.0, 21: 1.0, 24: 1.0}))\n",
      "Row(nostops=[u'speaking', u'words', u'wisdom,', u'let'], hash=SparseVector(50, {9: 1.0, 12: 1.0, 14: 1.0, 41: 1.0}))\n",
      "Row(nostops=[u'hour', u'darkness'], hash=SparseVector(50, {23: 1.0, 27: 1.0}))\n",
      "Row(nostops=[u'standing', u'right', u'front'], hash=SparseVector(50, {24: 1.0, 43: 1.0, 46: 1.0}))\n",
      "Row(nostops=[u'speaking', u'words', u'wisdom,', u'let'], hash=SparseVector(50, {9: 1.0, 12: 1.0, 14: 1.0, 41: 1.0}))\n",
      "Row(nostops=[u'let'], hash=SparseVector(50, {14: 1.0}))\n",
      "Row(nostops=[u'let'], hash=SparseVector(50, {14: 1.0}))\n",
      "Row(nostops=[u'let'], hash=SparseVector(50, {14: 1.0}))\n",
      "Row(nostops=[u'let'], hash=SparseVector(50, {14: 1.0}))\n"
     ]
    }
   ],
   "source": [
    "for e in idfDf.select(\"nostops\",\"hash\").take(10):\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
