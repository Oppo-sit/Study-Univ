{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"PYLIB\"]=os.path.join(os.environ[\"SPARK_HOME\"],'python','lib')\n",
    "sys.path.insert(0,os.path.join(os.environ[\"PYLIB\"],'py4j-0.10.1-src.zip'))\n",
    "sys.path.insert(0,os.path.join(os.environ[\"PYLIB\"],'pyspark.zip'))\n",
    "\n",
    "import pyspark\n",
    "myConf=pyspark.SparkConf()\n",
    "spark = pyspark.sql.SparkSession.builder\\\n",
    "    .master(\"local\")\\\n",
    "    .appName(\"myApp\")\\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"C:/Users/G312\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파일 내려받고 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "_trainDf = spark.read.format('com.databricks.spark.csv')\\\n",
    "    .options(header='true', inferschema='true')\\\n",
    "    .load(os.path.join(\"data\",\"kaggle\",\"titanic\",\"train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-----------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|testOrtrain|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-----------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|     |       S|      train|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|      train|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|     |       S|      train|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_trainDf.show(3, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+--------------------+------+----+-----+-----+------+------+-----+--------+\n",
      "|PassengerId|Pclass|                Name|   Sex| Age|SibSp|Parch|Ticket|  Fare|Cabin|Embarked|\n",
      "+-----------+------+--------------------+------+----+-----+-----+------+------+-----+--------+\n",
      "|        892|     3|    Kelly, Mr. James|  male|34.5|    0|    0|330911|7.8292|     |       Q|\n",
      "|        893|     3|Wilkes, Mrs. Jame...|female|47.0|    1|    0|363272|   7.0|     |       S|\n",
      "|        894|     2|Myles, Mr. Thomas...|  male|62.0|    0|    0|240276|9.6875|     |       Q|\n",
      "+-----------+------+--------------------+------+----+-----+-----+------+------+-----+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_testDf = spark.read.format('com.databricks.spark.csv')\\\n",
    "    .options(header='true', inferschema='true')\\\n",
    "    .load(os.path.join(\"data\",\"kaggle\",\"titanic\",\"test.csv\"))\n",
    "\n",
    "_testDf.show(3, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/test 파일 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, col\n",
    "_trainDf = _trainDf.withColumn('testOrtrain',lit('train'))\n",
    "_testDf = _testDf.withColumn('testOrtrain',lit('test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "_testDf = _testDf.withColumn('Survived',lit(99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- testOrtrain: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_trainDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- testOrtrain: string (nullable = false)\n",
      " |-- Survived: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_testDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked testOrtrain\n"
     ]
    }
   ],
   "source": [
    "for c in _trainDf.columns:\n",
    "    print c,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=_trainDf.select('PassengerId','Survived','Pclass','Name','Sex','Age',\\\n",
    "                   'SibSp','Parch','Ticket','Fare','Cabin','Embarked','testOrtrain')\\\n",
    "            .union(_testDf.select('PassengerId','Survived','Pclass','Name','Sex','Age',\\\n",
    "                   'SibSp','Parch','Ticket','Fare','Cabin','Embarked','testOrtrain'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test/Train 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+--------------------+\n",
      "|testOrtrain|Survived|                Name|\n",
      "+-----------+--------+--------------------+\n",
      "|       test|      99|    Kelly, Mr. James|\n",
      "|       test|      99|Wilkes, Mrs. Jame...|\n",
      "|       test|      99|Myles, Mr. Thomas...|\n",
      "|       test|      99|    Wirz, Mr. Albert|\n",
      "|       test|      99|Hirvonen, Mrs. Al...|\n",
      "|       test|      99|Svensson, Mr. Joh...|\n",
      "|       test|      99|Connolly, Miss. Kate|\n",
      "|       test|      99|Caldwell, Mr. Alb...|\n",
      "|       test|      99|Abrahim, Mrs. Jos...|\n",
      "|       test|      99|Davies, Mr. John ...|\n",
      "+-----------+--------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('testOrtrain','Survived','Name')\\\n",
    "    .filter(df['testOrtrain']=='test').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|testOrtrain|count|\n",
      "+-----------+-----+\n",
      "|      train|  891|\n",
      "|       test|  418|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df.testOrtrain).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+----+----+----+-----+-----+------+----+-----+--------+-----------+\n",
      "|PassengerId|Survived|Pclass|Name| Sex| Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|testOrtrain|\n",
      "+-----------+--------+------+----+----+----+-----+-----+------+----+-----+--------+-----------+\n",
      "|       1309|    1309|  1309|1309|1309|1046| 1309| 1309|  1309|1308| 1309|    1309|       1309|\n",
      "+-----------+--------+------+----+----+----+-----+-----+------+----+-----+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Missing 데이터의 처리\n",
    "from pyspark.sql.functions import count\n",
    "df.agg(*[count(c).alias(c) for c in df.columns]).show() #age와 fare 열에 결측값이 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Fare': 1, 'Age': 263, 'SibSp': 0, 'Survived': 0, 'Parch': 0}\n"
     ]
    }
   ],
   "source": [
    "def countNull(df,var):\n",
    "    return df.where(df[var].isNull()).count() #isNull로 결측값 확인\n",
    "\n",
    "missing = {c: countNull(df,c) for c in ['Survived','Age','SibSp','Parch','Fare']}\n",
    "\n",
    "print missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+------+------+-----+--------+-----------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|Ticket|  Fare|Cabin|Embarked|testOrtrain|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+------+------+-----+--------+-----------+\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|330877|8.4583|     |       Q|      train|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|244373|  13.0|     |       S|      train|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|  2649| 7.225|     |       C|      train|\n",
      "|         27|       0|     3|Emir, Mr. Farred ...|  male|null|    0|    0|  2631| 7.225|     |       C|      train|\n",
      "|         29|       1|     3|\"O'Dwyer, Miss. E...|female|null|    0|    0|330959|7.8792|     |       Q|      train|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+------+------+-----+--------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print df.filter(\"Age is NULL\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+------------------+----+----+-----+-----+------+----+-----+--------+-----------+\n",
      "|PassengerId|Survived|Pclass|              Name| Sex| Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|testOrtrain|\n",
      "+-----------+--------+------+------------------+----+----+-----+-----+------+----+-----+--------+-----------+\n",
      "|       1044|      99|     3|Storey, Mr. Thomas|male|60.5|    0|    0|  3701|null|     |       S|       test|\n",
      "+-----------+--------+------+------------------+----+----+-----+-----+------+----+-----+--------+-----------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print df.filter(\"Fare is NULL\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.8811376673\n",
      "33.2954792813\n",
      "Row(avg(Age)=29.881137667304014)\n",
      "Row(avg(Fare)=33.29547928134553)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F #age와 Fare의 평균갑 구하기\n",
    "\n",
    "avgAge=df.agg(F.avg(df['Age']).alias('meanAge')).collect()\n",
    "avgFare=df.agg(F.avg(df['Fare']).alias('meanFare')).collect()\n",
    "\n",
    "print avgAge[0]['meanAge']\n",
    "print avgFare[0]['meanFare']\n",
    "\n",
    "print df.groupBy().mean('Age').first()\n",
    "print df.groupBy().mean('Fare').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|               Age|\n",
      "+-------+------------------+\n",
      "|  count|              1046|\n",
      "|   mean|29.881137667304014|\n",
      "| stddev| 14.41349321127132|\n",
      "|    min|              0.17|\n",
      "|    max|              80.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe(['Age']).show() #age열에 대한 통계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|year|\n",
      "+----+\n",
      "|2019|\n",
      "|2020|\n",
      "|2021|\n",
      "|9999|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my = spark.createDataFrame([[2019], [2020], [2021], [None]], ['year'])\n",
    "my = my.fillna({'year':'9999'}) #Null 값을 대체하는 fillna 함수\n",
    "my.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when,isnull #isnull, when을 통해 결측값을 평균으로 대체\n",
    "df=df.withColumn(\"Age\", when(isnull(df['Age']), avgAge[0]['meanAge']).otherwise(df.Age))\n",
    "df=df.withColumn(\"Fare\", when(isnull(df['Fare']), avgFare[0]['meanFare']).otherwise(df.Fare))\n",
    "#df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22.0, 35.0]\n"
     ]
    }
   ],
   "source": [
    "quantiles=df.stat.approxQuantile('Age', [0.25,0.75], 0.0 )\n",
    "print quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.05 61.0\n"
     ]
    }
   ],
   "source": [
    "mid50 = quantiles[1]-quantiles[0]\n",
    "lower = quantiles[0] - 1.15*mid50\n",
    "upper = quantiles[1] + 2.0*mid50\n",
    "print lower, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+---+-----+-----+-------+------+-----+--------+-----------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex|Age|SibSp|Parch| Ticket|  Fare|Cabin|Embarked|testOrtrain|\n",
      "+-----------+--------+------+--------------------+------+---+-----+-----+-------+------+-----+--------+-----------+\n",
      "|          8|       0|     3|Palsson, Master. ...|  male|2.0|    3|    1| 349909|21.075|     |       S|      train|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female|4.0|    1|    1|PP 9549|  16.7|   G6|       S|      train|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male|2.0|    4|    1| 382652|29.125|     |       Q|      train|\n",
      "+-----------+--------+------+--------------------+------+---+-----+-----+-------+------+-----+--------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((df.Age<lower) | (df.Age>upper)).show(3,truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|   Sex|count|\n",
      "+------+-----+\n",
      "|female|  466|\n",
      "|  male|  843|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#성별 구분\n",
    "df.groupBy('Sex').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def getTitle(name):\n",
    "    title=None\n",
    "    if re.search(\".*Mr\\..*\", name): #남자 Mr\n",
    "        title=\"male\"\n",
    "    elif re.search(\".*[Miss|Mrs|Ms]\\..*\", name): #여자 Miss Mrs Ms\n",
    "        title=\"female\"\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male\n",
      "female\n",
      "female\n",
      "female\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "names=[\"Braund, Mr. Owen Harris\",\n",
    "       \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\",\n",
    "       \"Heikkinen, Miss. Laina\",\n",
    "       \"Ms.hello\",\n",
    "       \"No title\"]\n",
    "for n in names:\n",
    "    print getTitle(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "getTitleUdf = udf(getTitle, StringType())\n",
    "df = df.withColumn('Title', getTitleUdf(df['Name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------------------------------+------+------+\n",
      "|testOrtrain|Name                                        |Title |Sex   |\n",
      "+-----------+--------------------------------------------+------+------+\n",
      "|test       |Kelly, Mr. James                            |male  |male  |\n",
      "|test       |Wilkes, Mrs. James (Ellen Needs)            |female|female|\n",
      "|test       |Myles, Mr. Thomas Francis                   |male  |male  |\n",
      "|test       |Wirz, Mr. Albert                            |male  |male  |\n",
      "|test       |Hirvonen, Mrs. Alexander (Helga E Lindqvist)|female|female|\n",
      "|test       |Svensson, Mr. Johan Cervin                  |male  |male  |\n",
      "|test       |Connolly, Miss. Kate                        |female|female|\n",
      "|test       |Caldwell, Mr. Albert Francis                |male  |male  |\n",
      "|test       |Abrahim, Mrs. Joseph (Sophie Halaut Easu)   |female|female|\n",
      "|test       |Davies, Mr. John Samuel                     |male  |male  |\n",
      "+-----------+--------------------------------------------+------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('testOrtrain','Name','Title','Sex')\\\n",
    "    .filter(df['testOrtrain']=='test')\\\n",
    "    .show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "| Title|count|\n",
      "+------+-----+\n",
      "|  null|   19|\n",
      "|female|  533|\n",
      "|  male|  757|\n",
      "+------+-----+\n",
      "\n",
      "+------+-----+\n",
      "|   Sex|count|\n",
      "+------+-----+\n",
      "|female|  466|\n",
      "|  male|  843|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Title').count().show()\n",
    "df.groupBy('Sex').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- testOrtrain: string (nullable = false)\n",
      " |-- Title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|SurvivedD|count|\n",
      "+---------+-----+\n",
      "|      0.0|  549|\n",
      "|      1.0|  342|\n",
      "|     99.0|  418|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=df.withColumn(\"SurvivedD\",_trainDf['Survived']\\\n",
    "    .cast(\"double\"))\\\n",
    "    .drop('Survived')\n",
    "\n",
    "df.groupBy('SurvivedD').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-----------+------+---------+\n",
      "|PassengerId|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|testOrtrain| Title|SurvivedD|\n",
      "+-----------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-----------+------+---------+\n",
      "|          1|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|     |       S|      train|  male|      0.0|\n",
      "|          2|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|      train|female|      1.0|\n",
      "|          3|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|     |       S|      train|female|      1.0|\n",
      "|          4|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|      train|female|      1.0|\n",
      "|          5|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05|     |       S|      train|  male|      0.0|\n",
      "+-----------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-----------+------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "#from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "SexIndexer = StringIndexer(inputCol=\"Sex\", outputCol=\"SexI\")\n",
    "EmbarkedIndexer = StringIndexer(inputCol=\"Embarked\", outputCol=\"EmbarkedI\")\n",
    "\n",
    "#PclassIndexer = StringIndexer(inputCol=\"Pclass\", outputCol=\"SexI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "va = VectorAssembler(inputCols=[\"Pclass\",\"SexI\",\"Age\",\"SibSp\",\"Parch\",\\\n",
    "                                \"Fare\",\"EmbarkedI\"],\\\n",
    "                     outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[SexIndexer,EmbarkedIndexer,va])\n",
    "model = pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDf = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|SurvivedD|            features|\n",
      "+---------+--------------------+\n",
      "|      0.0|[3.0,0.0,22.0,1.0...|\n",
      "|      1.0|[1.0,1.0,38.0,1.0...|\n",
      "|      1.0|[3.0,1.0,26.0,0.0...|\n",
      "|      1.0|[1.0,1.0,35.0,1.0...|\n",
      "|      0.0|(7,[0,2,5],[3.0,3...|\n",
      "|      0.0|[3.0,0.0,29.88113...|\n",
      "|      0.0|(7,[0,2,5],[1.0,5...|\n",
      "|      0.0|[3.0,0.0,2.0,3.0,...|\n",
      "|      1.0|[3.0,1.0,27.0,0.0...|\n",
      "|      1.0|[2.0,1.0,14.0,1.0...|\n",
      "+---------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDf.select('SurvivedD','features').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all num of rows:  1309\n"
     ]
    }
   ],
   "source": [
    "print \"all num of rows: \",myDf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=myDf.filter(myDf['testOrtrain']=='train')\n",
    "testDf=myDf.filter(myDf['testOrtrain']=='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- testOrtrain: string (nullable = false)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- SurvivedD: double (nullable = true)\n",
      " |-- SexI: double (nullable = true)\n",
      " |-- EmbarkedI: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test num of rows:  418\n"
     ]
    }
   ],
   "source": [
    "print 'test num of rows: ',testDf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf,validateDf = train.randomSplit([0.7,0.3],seed=11) #검증/빌딩을 위해 두 그룹으로, 랜덤으로 나눈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "628"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " validateDf.count() #검증 DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- testOrtrain: string (nullable = false)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- SurvivedD: double (nullable = true)\n",
      " |-- SexI: double (nullable = true)\n",
      " |-- EmbarkedI: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|SurvivedD|count|\n",
      "+---------+-----+\n",
      "|      0.0|  383|\n",
      "|      1.0|  245|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDf.groupBy('SurvivedD').count().show() #여기부터 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    " \n",
    "# regPara: lasso regularisation parameter (L1)\n",
    "lr = LogisticRegression().\\\n",
    "    setLabelCol('SurvivedD').\\\n",
    "    setFeaturesCol('features').\\\n",
    "    setRegParam(0.0).\\\n",
    "    setMaxIter(100).\\\n",
    "    setElasticNetParam(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel=lr.fit(trainDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrDf = lrModel.transform(validateDf) #여기서부터 예측(predition/probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- testOrtrain: string (nullable = false)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- SurvivedD: double (nullable = true)\n",
      " |-- SexI: double (nullable = true)\n",
      " |-- EmbarkedI: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lrDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+----------+\n",
      "|SurvivedD|       rawPrediction|         probability|prediction|\n",
      "+---------+--------------------+--------------------+----------+\n",
      "|      1.0|[-0.7209575821080...|[0.32718215168700...|       1.0|\n",
      "|      1.0|[-2.0503227895482...|[0.11401976925515...|       1.0|\n",
      "|      1.0|[-1.9554360708280...|[0.12396181876919...|       1.0|\n",
      "|      1.0|[-1.1467078201107...|[0.24109092679847...|       1.0|\n",
      "|      1.0|[-1.4698503211520...|[0.18696536548151...|       1.0|\n",
      "|      0.0|[1.69472254018706...|[0.84484421073581...|       0.0|\n",
      "|      1.0|[1.26032179504787...|[0.77908149803135...|       0.0|\n",
      "|      1.0|[-1.4501313540239...|[0.18998135132665...|       1.0|\n",
      "|      1.0|[-0.0619658876835...|[0.48451348315217...|       1.0|\n",
      "|      0.0|[2.56037173163627...|[0.92826721424349...|       0.0|\n",
      "|      1.0|[-0.8920008140330...|[0.29069710229074...|       1.0|\n",
      "|      0.0|[-1.2464028691324...|[0.22332344045916...|       1.0|\n",
      "|      0.0|[1.95032687007954...|[0.87548227929311...|       0.0|\n",
      "|      1.0|[-0.8497256926713...|[0.29949040291388...|       1.0|\n",
      "|      0.0|[-0.6189589760433...|[0.35001825308221...|       1.0|\n",
      "|      0.0|[1.73615921896138...|[0.85019855753063...|       0.0|\n",
      "|      0.0|[3.56369823671166...|[0.97244684148754...|       0.0|\n",
      "|      0.0|[0.86690971886304...|[0.70410226817396...|       0.0|\n",
      "|      1.0|[-1.5870055403151...|[0.16980561361907...|       1.0|\n",
      "|      1.0|[0.86052411729901...|[0.70277014583679...|       0.0|\n",
      "+---------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lrDf.select('SurvivedD','rawPrediction','probability','prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator #여기서부터 평가\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol = 'prediction',\\\n",
    "                                          labelCol='SurvivedD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7919513103962241"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(lrDf) #약 80퍼센트 -> 짐승보다 낫다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
