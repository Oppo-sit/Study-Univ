#설치하는게 어렵다. 하지만 그대로 따라가면 나중에 오류가 없을것이다.

참고로 나는 윈도우 유저이고 다른 것은 써본 적이 없기 때문에 다른 OS 사용자들은 욕하면서 나가셔도 좋다.

1. 설치하는 버전.

  아나콘다 (Python 2)

    https://www.anaconda.com/distribution/

  여기서 python 2.7버전으로 설치하자.(64bit버전 권장)

  JDK 9

    https://download.java.net/java/GA/jdk9/9.0.4/binaries/openjdk-9.0.4_windows-x64_bin.tar.gz

  만약 오류가 생겨서 JDK 8으로 낮추려면,

    https://github.com/frekele/oracle-java/releases/download/8u212-b10/jdk-8u212-windows-x64.exe

  다만, 9버전은 압축을 풀어서 환경변수 설정을 해주기만 하면 되고 아래버전은 설치하고 환경변수가 설정되었는지 확인해봐야한다.

  Spark 2.0.0 with Hadoop 2.7

    https://archive.apache.org/dist/spark/spark-2.0.0/spark-2.0.0-bin-hadoop2.7.tgz

  winutils(for hadoop 2.7)

  이건 따로 첨부하겠다.

2. 순서

  일단 아나콘다부터 설치한다.

  설치 상태줄이 마지막에서 멈출텐데 버그 아니다. 가만히 냅두자.
  대신, 위에 있는 링크 따라 나머지도 다 다운을 받고 압축을 풀어준다.(단, JDK 8은 설치 버전이니 아나콘다가 다 설치된 후 설치한다.)
  아나콘다까지 모두 설치되었다면, 환경변수를 설정해주어야 한다.

  PYTHON

    python이 어딨느냐? 바로 사용자 디렉토리에 있다.
    어딨는지 모르겠으면 C:\Users 들가서 자기 계정 이름 적혀있는데로 들어가보자.
    그러면 ANACONDA 2라는 곳이 보인다.
    바로 그 곳이 환경변수로 설정할 디렉토리다.
    근데 환경변수 어떻게 설정하는지 모른다?
    윈도우 10은 매우 친절하다. 아래 상태표시줄에 검색하는 데에 환경변수 치면 친절하게 나온다. 
    그거 클릭하고 맨 아래 오른쪽에 환경 변수(라고 적혀있나?) 그 버튼 누르면 환경 변수 창이 뜬다. 
    그리고 열면 사용자와 시스템 둘로 나뉘어 있는데 계정 하나만 쓰는 사람들은 신경 안쓰고 둘 중 하나 선택
    (하나는 사용자, 하나는 시스템 이렇게 하는 사이코는 되지 말자)
    거기서 새로 만들기를 눌러주면 변수 이름과 변수 값을 적어주는 칸이 뜨는데 이름은 멋대로 해도 되지만 값은 안된다.
    그럼 값은 뭐냐? 바로 디렉토리의 주소이다. 
    C:\Users\(계정 이름)\Anaconda2 가 변수의 값이 되는 것. 그럼 파이썬은 끝난다.
    
  JAVA
    
    JAVA는 어렵지 않다. 자신이 압축 푼 디렉토리가 환경 변수의 값이 된다.
    이름은 JAVA_HOME을 권장한다.
    
    
  SPARK
  
    SPARK 또한 JAVA와 같다. 
    이름은 SPARK_HOME을 권장한다.
    
  HADOOP
  
    하둡은 못본 것 같은데, winutils.exe가 하둡이라고 생각하면 된다.
    즉, 환경 변수의 값은 winutils.exe의 위치가 된다.
    여기서 오류 없이 가려면 C드라이브(윈도우 설치한 드라이브)에 HADOOP_HOME 폴더 만들고 안에 bin 폴더를 만든다.
    거기다가 winutils.exe를 만든 뒤, 이 디렉토리를 환경변수의 값으로
    => C:\HADOOP_HOME\bin 
    이름은 HADOOP_HOME을 권장한다.
    그리고 추가적으로 C드라이브에 tmp\hive를 생성, 환경변수 설정이 제대로 되었다면
    winutils chmod 777 c:\tmp\hive를 명령 프롬프트(관리자 권한)에 복사해서 실행한다.
    (hive 폴더에 권한 부여해야 함)
    
   다 설정해준 것 같지만 하나가 남았다. 'PATH'라는 환경변수에 이들을 입력하는 것. 
  만약 path가 하나다? 그럼 그 줄에 ;으로 경로를 구분시켜주자.
  거기에 뭐 적을거냐고?
  변수 이름 적을 것이다.
 
    Python -> %(파이썬 변수 이름)%
    JAVA -> %JAVA_HOME%\bin
    SPARK -> %SPARK_HOME%\bin
    HADOOP_HOME -> %HADOOP_HOME%
    
    
3. TEST

  환경 변수가 제대로 설정되어 있는지 확인하려면 이 코드를 명령 프롬프트(이것도 관리자 권한)으로 쳐보자.

    python --version
  
    java -version
    javac -version
  
    pyspark
  
  하둡은 chmod 실행하면서 테스트 같이 된다.
  참고로, 버전도 나오니 내가 원하는 버전이 설치되었는지 확인도 가능하다.

4. 사용할 프로그램

  코딩에 사용할 프로그램은 Jupyter Notebook 이다. 뒤에 (Python 2)이런 식으로 버전 명시되어 있으니 제대로 보고 클릭해서 ㅈ되지 말자.
  만약 안되면 대체제로 DataBricks를 쓰면 된다고 하는데 나는 오류가 안떠서 써본 적 없음. ㅎ
 
 
꼭 잘 되길 기원합니다.
    
